{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 3 - Ciência dos Dados\n",
    "\n",
    "# Ciência dos Dados 2019\n",
    "\n",
    "### Alunos:\n",
    "- Felipe Junqueira\n",
    "- Giovana Campedelli\n",
    "- Gabriela Choichit\n",
    "- João Roxo\n",
    "\n",
    "### Link para base de dados:\n",
    "\n",
    "- https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da base de dados coletada foi utilizado a biblioteca 'scikit-learn' para assim usufruir das técnicas Naive Bases e Decision tree classifier para classificação dos resultados do Jogo da Velha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tictac.jpg\" height=10 width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto tinha como objetivo analisar a predição de ganho do X no famoso Jogo da Velha. Para tal, foi estudado um dataframe com mais de 900 probabilidades de jogadas começadas pelo X, essas que poderiam resultar em positivo ou negativo, onde um significava o ganho de X e o outro a perda ou o empate, respectivamente. Assim prevendo incidência de cada resultado e calculando a acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para melhor compreensão durante o relatório, criamos uma imagens que relaciona cada posição (casa do tabuleiro) a um nome prático e o nome contido no dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"casas.jpeg\" height=300 width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise do dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de dados obtida estava dividida em colunas com as posições do tabuleiro, e cada linha representa a jogada completa, ou seja, tinham strings (X, O, B), o que significava a posição de jogada de cada um dos oponentes e o espaço em branco. A última coluna da base era a variável de saída da análise, sendo positiva, quando o jogador X ganhava, ou negativa, quando o jogador X perdia ou quando dava empate.\n",
    "\n",
    "Como as informações nas linhas estavam no formato de strings, foi necessário transformá-las em números binários para ser possível fazer a análise. Então, por exemplo, na coluna Top Left onde havia um X, virou três colunas de Top Left, a primeira com 0(Que representa o B), a segunda com 0 (Que representa o O) e a última com 1 (vez que representava o X). Para realizar essa operação foi usado o dummify, assim a base passou a ter 27 colunas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira Técnica de Análise - Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes é uma ferramenta que calcula probabilidades seguindo o “Teorema de Bayes”, ou seja, analisando a frequência de cada variável e analisando o possível outcome que cada uma traria.\n",
    "\n",
    "Com isso em mente, inicialmente, foi feito uma análise utilizando a técnica de classificação Naive-Bayes. Para tal, foi preciso treinar a base de dados e avaliar se a classificação feita estava de acordo com a original. [link do notebook com análise do Naive-Bayes](Projeto_3_naive_bayes.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "A partir da tabela obtida pelo dummify, foi utilizado o naive bayes para prever a probabilidade do resultado ser positivo dado as posições dos jogadores.\n",
    "\n",
    "O primeiro teste foi feito com uma base de treinamento que consistia em 75% dos dados e uma base de teste de 15%, com essa proporção é possível ter uma acurácia de 75%\n",
    "\n",
    "O resultado foi bom, porém foram feitas iterações visando aumentar a acurácia, as primeiras constituíram-se de aumentar a base de treinamento para observar se o resultado se alterava proporcionalmente. Inicialmente mudamos para 85% de treino, o que manteve a acurácia em 75%, depois aumentamos para 90%, o que fez com que a acurácia caísse para 70%, e por fim 95% de treinamento, que teve uma acurácia de 75% novamente.\n",
    "\n",
    "Como pôde ser observado, alterar o tamanho da base de treinamento não influenciou muito a acurácia, outras iterações foram feitas. O grupo discutiu e formulou a hipótese (ataraves de uma rápida pesquisa em sala para diversos jogadores) de que a posição B3 (bottom-middle) não era muito utilizada, então, para averiguar isso, essa coluna foi retirada do dataset. Foi rodado o programa novamente, o que resultou em uma acurácia de 75% novamente. Com isso, é possível concluir que a casa da coluna do meio e da fileira de baixo realmente não é tão relevante e não impacta tanto outcome.\n",
    "\n",
    "Depois disso, uma nova hipótese foi formulada, a de que a casa do meio era a mais usada por todos e a que desencadeava o maior número de possibilidades. Então a casa B3 (bottom-middle) foi colocada de volta na e foi tirada a casa do B2 (middle-middle). Como pensado, isso alterou a acurácia depois de rodar o programa, ela caiu para 69%, o que significa que esta casa realmente influencia os resultados do jogo.\n",
    "\n",
    "Como a acurácia não diminuiu de forma tão significativa, as próximas iterações consistiram-se em eliminar jogadas estratégicas, então a primeira combinação que foi impossibilitada foi a da A1 (top-left), A3 (top-right) e A3, e com isso novamente foi rodado o naive bayes, o que resultou em uma acurácia de 72,5%, e segunda combinação era semelhante porém tirava também a casa do meio, assim a acurácia foi de aproximadamente 70%. \n",
    "\n",
    "Por fim, a última iteração foi remover todas as casas menos a da A1 (top-left) e B2 (middle-middle), que gerou um resultado de também aproximadamente 70% de acurácia.\n",
    "\n",
    "Foi observado que apesar das mudanças feitas, o resultado não variava muito, com base nisso, foi possível concluir que o naive bayes talvez não fosse a melhor ferramenta para analisar essa base de dados. O motivo disso é que o programa parece chutar se o resultado do jogo é positivo ou negativo com base na proporção do dataframe (positivo 626, negativo 332), esse erro é mais conhecido como erro de bayes; dessa forma, como há mais outcomes positivos na base de dados o programa tende chutar com essa proporção. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunta Técnica de Análise - Decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o objetivo de realmente averiguar as chances de uma pessoa ganhar o jogo da velha baseado nas suas primeiras jogadas, foi utilizada uma outra ferramenta de predição, o decision tree classifier, que consiste em prever o resultado final a partir de uma árvore de decisão, onde cada escolha influencia a próxima. [link do notebook com análise do Decision Tree](Projeto_3_decision_tree_classifier.ipynb)\n",
    "\n",
    "Decision tree classifier é uma técnica de machine learning que divide os dados de acordo com um determinado parâmetro, neste caso, o preenchimento de cada posição do tabuleiro, e formando uma 'arvore' de possibilidades para tais classificações. \n",
    "\n",
    "Primeiramente foi feito o dummify, como na naive bayes, para deixar as colunas com resultados qualitativos para que assim fosse possível analisar os dados. Depois disso, a tabela foi dividida entre treinamento e teste com o uso da Random Seed para que fosse igual a base usada previamente quando rodado o Naive Bayes, isso garantiria que a comparação entre as duas técnicas seria fidedigna.\n",
    "\n",
    "A partir disso, foi implementado o código que faria a árvore. Com o decision tree feito, foi analisado primeiro a probabilidade de ganho do X com apenas uma casa do tabuleiro preenchida, verificando a acurácia dos resultados. O próximo passo foi analisar o preenchimento das demais casas gradualmente.\n",
    "\n",
    "Com apenas uma casa preenchida, o classifier teve uma acurácia de 0.70%, o que já é um resultado bom, com duas casas foi muito próximo, já com três, a acurácia subiu para 0.74%, que é semelhante aos valores obtidos com o naive bayes, porém agora com uma real analise da base pelo algoritmo. Com quatro casas subiu ainda mais, para 0.82%. Com cinco foi para 0.84%, depois para 0.91%, 0.93%, 0.94%, para por fim, com as nove casas preenchidas, atingir uma acurácia de 95%. Para ilustrar esses resultados, foi feito um gráfico, de acurácia por casas preenchidas, que mostra uma relação crescente entre os dois (figura abaixo), o que faz sentido visto que com mais casas preenchidas, é mais fácil de prever o ganhador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"graphic_acc.png\" height=300 width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"carseats_tree2.png\" height=100 width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode ser verificado a raiz deste decision tree, é a posição B2 (middle-middle), ou seja, a posição que o algoritmo considera mais decisivo em diversas tomadas de decisão. \n",
    "\n",
    "Assim, podemos considerar tal algoritmo uma boa tática de análise, pois este mostra uma ideia que o algoritmo aprendeu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terceira Técnica de Análise - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa técnica de aprendizagem supervisionada parte do decision tree classifier, ou seja, junta diversas arvores de classificação em uma \"floresta\", combinando-as.\n",
    "[link do notebook com análise do Random Forest](Projeto_3_random_forest.ipynb)\n",
    "\n",
    "Foi seguido o mesmos princípios da análise pelo decision tree feita a cima, contudo os resultados foram um pouco diferentes. \n",
    "\n",
    "Com apenas uma casa preenchida, o classifier teve uma acurácia de 64%, um pouco abaixo compando com a árvore anterior; com duas casas foi muito próximo, já com três, a acurácia subiu para 69%. Com quatro casas subiu drasticamente chegando a 82%. Por fim, com as oito casa, foi possivel atingir o maior valor de acurácia9 deste, sendo 94%. E novamentefoi feito um gráfico, de acurácia por casas preenchidas, que mostra uma relação crescente entre os dois (figura abaixo). Faz sentido, assim como o decision tree, contudo com 9 casa preenchidas o valor de acuracia cai um pouco; assim, é preferivél seguir a análise anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"praphic_acc2.png\" height=300 width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso de análise do resultado de uma partida de jogo da velha, o decision tree classifier foi mais eficiente, ele foi capaz de analisar as probabilidades a cada jogada com uma acurácia alta, enquanto o naive bayes não conseguiu realizar essa tarefa de maneira tão adequada.\n",
    "\n",
    "A partir dos dados, o programa aprendeu que a casa que mais influencia o resultado do jogo é a da coluna do meio e da fileira do meio, então o primeiro galho da árvore é esse, e as ramificações são as outras casas a serem preenchidas. Assim, o preenchimento de tal posição é, na maioria das vezes, decisivo para ganhar a partida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
