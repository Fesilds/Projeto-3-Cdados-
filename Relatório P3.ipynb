{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 3 - Ciência dos Dados\n",
    "\n",
    "# Ciência dos Dados 2019\n",
    "\n",
    "### Alunos:\n",
    "- Felipe Junqueira\n",
    "- Giovana Campedelli\n",
    "- Gabriela Choichit\n",
    "- João Roxo\n",
    "\n",
    "### Link para base de dados:\n",
    "\n",
    "- https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da base de dados coletada vamos usar a biblioteca ''scikit-learn'' para assim usufruir da técnica Naive Bases para classificação, no caso do jogo da velha: o resultado do jogo.\n",
    "\n",
    "Feita a primeira análise vamos utilizar de outros algorítimos para classificá-los novamente e assim comparar os resultados obtidos.\n",
    "\n",
    "Finalmente obteremos o resultado previsto e o melhor algoritmo para prever o resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Este projeto tinha como objetivo analisar a predição de ganho do X no famoso Jogo da Velha. Para tal, foi estudado um dataframe com mais de 900 probabilidades de jogadas começadas pelo X, essas que poderiam resultar em positivo ou negativo, onde um significava o ganho de X e o outro a perda ou o empate, respectivamente. Assim prevendo incidência de cada resultado e calculando a acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    link do notebook contendo a análise por naive bayes: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Inicialmente, foi feito uma análise utilizando a técnica de classificação Naive-Bayes. Para tal, foi preciso treinar a base de dados e avaliar se a classificação feita estava de acordo com a original. \n",
    "    A base de dados obtida estava dividida em colunas com as posições do tabuleiro, e cada linha representa a jogada completa, ou seja, tinham strings (X, O, B), o que significava a posição de jogada de cada um dos oponentes e o espaço em branco. A última coluna da base era a variável de saída da análise, sendo positiva, quando o jogador X ganhava, ou negativa, quando o jogador X perdia ou quando dava empate.\n",
    "    Como as informações nas linhas estavam no formato de strings, foi necessário transformá-las em números binários para ser possível fazer a análise. Então, por exemplo, na coluna Top Left onde havia um X, virou três colunas de Top Left, a primeira com 0(Que representa o B), a segunda com 0 (Que representa o O) e a última com 1 (vez que representava o X). Para realizar essa operação foi usado o dummify, assim a base passou a ter 27 colunas. A partir dessa nova tabela foi feito o naive bayes para prever a probabilidade do resultado ser positivo dado as posições dos jogadores.\n",
    "    O primeiro teste foi feito com uma base de treinamento que consistia em 75% dos dados e uma base de teste de 15%, com essa proporção tivémos uma acurácia de 75%\n",
    "    O resultado foi bom, porém foram feitas iterações visando aumentar a acurácia, as primeiras constituiram-se de aumentar a base de treinamento para observar se o resultado se alterava proporcionalmente. Inicialmente mudamos para 85% de treino, o que manteve a acurácia em 75%, depois aumentamos para 90%, o que fez com que a acurácia caísse para 70%, e por fim 95% de treinamento, que teve uma acurácia de 75% novamente.\n",
    "    Como pôde ser observado, alterar o tamanho da base de treinamento não influenciou muito a acurácia, outras iterações foram feitas. O grupo discutiu e formulou a hipótese de que a casa do meio da coluna de baixo não era muito utilizada, então, para averiguar isso, essa coluna foi retirada do dataset. Foi rodado o programa novamente, o que resultou em uma acurácia de 75% novamente. Com isso, é possível concluir que a casa da coluna do meio e da fileira de baixo realmente não é tão relevante e não impacta tanto outcome.\n",
    "    Depois disso, uma nova hipótese foi formulada, a de que a casa do meio era a mais usada por todos e a que desencadeava o maior número de possibilidades. Então a casa da coluna do meio de baixo foi colocada de volta na e foi tirada a casa do meio. Como pensado, isso alterou a acurácia depois de rodar o programa, ela caiu para 69%, o que significa que esta casa realmente influencia os resultados do jogo.\n",
    "    Como a acurácia não diminuiu de forma tão significativa, as próximas iterações consistiram-se em eliminar jogadas estratégicas, então a primeira combinação que foi impossibilitada foi a da coluna de cima na esquerda e direita e a de baixo da esquerda, e com isso novamento foi rodado o naive bayes, o que resultou em uma acurácia de 72,5%, e segunda combinação era semelhante porém tirava também a casa do meio, assim a acurácia foi de aproximadamente 70%. Por fim, a última iteração foi remover todas as casas menos a da esquerda de cima e a do meio, que gerou um resultado de também aproxiamdamente 70% de acurácia.\n",
    "    Foi observado que apesar das mudanças feitas, o resultado não variava muito, com base nisso, foi possível concluir que o naive bayes talves não fosse a melhor ferramenta para analisar essa base de dados, o motivo disso é que o programa parece chutar se o resultado do jogo é positivo ou negativo quase que aleatoriamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Por conta disso, com o objetivo de realmente averiguar as chances de uma pessoa ganhar o jogo da velha baseado nas suas primeiras jogadas, foi utilizada uma outra ferramenta de predição, o decision tree classifier, que consiste em prever o resultado final a partir de uma árvore de decisão, onde cada escolha influencia a próxima.\n",
    "        Primeiramente foi feito o dummify, como na naive bayes, para deixar as colunas com resultados qualitativos para que assim fosse possível analisar os dados. Depois disso, a tabela foi divida entre treinamento e teste com o uso da Random Seed para que fosse igual a base usada previamente quando rodado o Naive Bayes, isso garantiria que a comparação entre as duas técnicas seria fidedigna.\n",
    "        A partir disso, foi implementado o código que faria a árvore. Com o decision tree feito (figura no notebook da decision tree), foi analisado primeiro a probabilidade de ganho do X com apenas uma casa do tabuleiro preenchida, verificando a acurácia dos resultados. O próximo passo foi analisar o preenchimento das demais casas gradualmente.\n",
    "        Com apenas uma casa preenchida, o classifier teve uma acurácia de 0.70%, o que já é um resultado bom, com duas casas foi muito próximo, já com três, a acurácia subiu para 0.74%, que é semelhante aos valores obtidos com o naive bayes, porém agora com uma real analise da base pelo algoritimo. Com quatro casas subiu ainda mais, para 0.82%. Com cinco foi para 0.84%, depois para 0.91%, 0.93%, 0.94%, para por fim, com as nove casas preenchidas, atingir uma acurácia de 95%. Para ilustrar esses resultados, foi feito um gráfico, de acurácia por casas preenchidas, que mostra uma relação crescente entre os dois (figura abaixo), o que faz sentido visto que com mais casas preenchidas, é mais fácil de prever o ganhador.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
